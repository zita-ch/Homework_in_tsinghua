{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zita\\miniconda2\\envs\\python35\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: use options instead of chrome_options\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.027283668518066\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from heapq import * \n",
    "import hashlib\n",
    "import threading\n",
    "from pyhanlp import *\n",
    "from selenium import webdriver\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--disable-gpu')\n",
    "chrome_options.add_argument('--ignore-ssl-errors')\n",
    "chrome_options.add_argument('enable-automation')\n",
    "chrome_options.add_argument('--window-size=1920,1080')\n",
    "chrome_options.add_argument('--disable-extensions')\n",
    "chrome_options.add_argument('--dns-prefetch-disable')\n",
    "driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "driver.set_page_load_timeout(2)\n",
    "\n",
    "max_num=60\n",
    "head = {        'Connection': 'Keep-Alive',\n",
    "        'Accept': 'text/html, application/xhtml+xml, */*',\n",
    "        'Accept-Language': 'en-US,en;q=0.8,zh-Hans-CN;q=0.5,zh-Hans;q=0.3',\n",
    "        'Accept-Encoding': 'gzip, deflate',\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36'\n",
    "       }\n",
    "\n",
    "def baidu_find(url):\n",
    "    #0即深网 1即明网 -1即被封\n",
    "    keyword=urllib.parse.quote(url)\n",
    "    url2=r'https://www.baidu.com/s?tn=02003390_14_hao_pg&ie=UTF-8&wd=site%3A'+keyword+r'&rsv_spt=1&rsv_iqid=0xdb5b72850006626d&issp=1&f=8&rsv_bp=1&rsv_idx=2&ie=utf-8&tn=02003390_14_hao_pg&rsv_enter=0&rsv_dl=tb&rsv_sug3=6&rsv_sug1=6&rsv_sug7=101&rsv_btype=i&prefixsug=sdasd&rsp=0&inputT=1704&rsv_sug4=4371'\n",
    "    res=requests.get(url2,headers=head)\n",
    "    res.encoding='utf-8'\n",
    "\n",
    "    flag1=len(re.findall(r'很抱歉，没有找到',res.text))\n",
    "    flag2=len(re.findall(r'<title>百度安全验证</title>',res.text))\n",
    "    if flag2>0:\n",
    "        return -1 #被封了,找个屁\n",
    "    elif flag1>0:\n",
    "        return 0 #没被封，没找到\n",
    "    else:\n",
    "        return 1 #没被封，找到了\n",
    "\n",
    "def md5_(s):\n",
    "    m1 = hashlib.md5()\n",
    "    m1.update(s.encode(\"utf-8\"))\n",
    "    token = m1.hexdigest()\n",
    "    return token[0:32:5]\n",
    "mode=re.compile(r'http[s]?://(.*)')\n",
    "begin_t=time.time()\n",
    "md5s=[0 for x in range(16**7)]\n",
    "print(time.time()-begin_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "waiting_list= collections.deque()\n",
    "\n",
    "heap = [] #for 更新事件 每次取出预定时间最小的\n",
    "\n",
    "##        \n",
    "class url_class:\n",
    "    def __init__(self,url=\"\"):\n",
    "        self.rank=int(4*len(re.findall(r'/',url))+1*len(re.findall('\\?',url))+1*len(re.findall('=',url)) \\\n",
    "        +1*len(re.findall(r'#',url))-3*len(re.findall(r'index',url))) #rank越大越不重要\n",
    "        self.url=url\n",
    "    def __lt__(self, other):\n",
    "        return self.rank < other.rank\n",
    "    def __gt__(self, other):\n",
    "        return self.rank > other.rank\n",
    "    def __eq__(self,other):\n",
    "        return self.rank == other.rank\n",
    "    def __ne__(self,other):\n",
    "        return self.rank != other.rank\n",
    "    def __le__(self,other):\n",
    "        return self.rank <= other.rank\n",
    "    def __ge__(self,other):\n",
    "        return self.rank >= other.rank\n",
    "    def __cmp__(self,other):\n",
    "        return cmp(self.rank,other.rank)\n",
    "##广度优先套优先级\n",
    "\n",
    "class update_event:\n",
    "    def __init__(self,deltat=30,url=\"\"):\n",
    "        self.set_time=time.time()+deltat\n",
    "        self.url=url_class(url)\n",
    "    def __lt__(self, other):\n",
    "        return self.set_time < other.set_time\n",
    "    def __gt__(self, other):\n",
    "        return self.set_time > other.set_time\n",
    "    def __eq__(self,other):\n",
    "        return self.set_time == other.set_time\n",
    "    def __ne__(self,other):\n",
    "        return self.set_time != other.set_time\n",
    "    def __le__(self,other):\n",
    "        return self.set_time <= other.set_time\n",
    "    def __ge__(self,other):\n",
    "        return self.set_time >= other.set_time\n",
    "    def revisit(self):\n",
    "        global waiting_list\n",
    "        waiting_list.append(self.url)\n",
    "        waiting_list=collections.deque(sorted(waiting_list)) #按照了rank来排序  在同样的rank下先进先出\n",
    "\n",
    "def heap2wl():\n",
    "    cur_time=time.time()\n",
    "    while (len(heap)>0 and heap[0].set_time<=cur_time):\n",
    "        event_top=heappop(heap)\n",
    "        event_top.revisit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#爬取url中内容\n",
    "link_wait_num=0\n",
    "link_finish_num=0\n",
    "s = requests.session()\n",
    "s.keep_alive = False\n",
    "url_kw={}\n",
    "table=open('url_table.csv','w')\n",
    "abandon=0\n",
    "def gettitle(soup):\n",
    "    try:\n",
    "        return (soup.title.string)\n",
    "    except:\n",
    "        try:\n",
    "            return (soup.find('h1').string)\n",
    "        except:\n",
    "            try:\n",
    "                return (soup.find('h2').string)\n",
    "            except:\n",
    "                try:\n",
    "                    return (soup.find('h3').string)\n",
    "                except:\n",
    "                    return (\"\")\n",
    "\n",
    "def get_keywords(soup,num=60):\n",
    "    content=soup.get_text().replace('\\n',' ').strip()\n",
    "    return list(HanLP.extractKeyword(content,num))\n",
    "\n",
    "def sim(kw_list1,kw_list2):\n",
    "    num_inter=0\n",
    "    num_union=len(kw_list1)\n",
    "    for w in kw_list2:\n",
    "        if w in kw_list1:\n",
    "            num_inter+=1\n",
    "        else:\n",
    "            num_union+=1\n",
    "    return float(num_inter)/float(num_union)\n",
    "        \n",
    "\n",
    "def search_href(soup):\n",
    "    global link_wait_num\n",
    "    if link_wait_num>=max_num*2:\n",
    "        return\n",
    "    if soup is None:\n",
    "        return\n",
    "    for a in soup.find_all('a', href=True,recursive=False):\n",
    "        if a.get_text(strip=True): \n",
    "            new_url=a['href']\n",
    "            link=re.findall(mode,new_url)\n",
    "            if(len(link)>0):\n",
    "                templink=link[0].rstrip(r\"/\")\n",
    "                md5_dec=int(md5_(templink),16)\n",
    "                if md5s[md5_dec]==0: #md5 deduplicate\n",
    "                    global waiting_list\n",
    "                    waiting_list.append(url_class(templink))\n",
    "                    waiting_list=collections.deque(sorted(waiting_list))\n",
    "                    md5s[md5_dec]=1 #仅在新网页引入时判断了md5，所以起点网站md5要手动置为1\n",
    "                    link_wait_num+=1\n",
    "                    if link_wait_num>=max_num*2:\n",
    "                        return\n",
    "\n",
    "def url_spider(url):\n",
    "    global link_finish_num\n",
    "    if link_finish_num>=max_num:\n",
    "        return\n",
    "    try:\n",
    "        driver.get(r'http://'+url)\n",
    "    except:\n",
    "        driver.execute_script('window.stop()')\n",
    "    try:\n",
    "        data = driver.page_source\n",
    "        soup=BeautifulSoup(data)\n",
    "    except:\n",
    "        return\n",
    "    if soup is None:\n",
    "        return\n",
    "    #print(soup)####debuging\n",
    "    #do something on soup/collect info\n",
    "    try:\n",
    "        temp_kw=get_keywords(soup.body)\n",
    "        ### de-mirror\n",
    "        for k in url_kw.values():\n",
    "            if sim(k,temp_kw)>0.8: #相似度过高视作镜像\n",
    "                global abandon\n",
    "                abandon=1\n",
    "                print('abandoned: ',url)\n",
    "                return\n",
    "        ###\n",
    "        url_kw[url]=temp_kw\n",
    "    except:\n",
    "        #print(soup.body)\n",
    "        return\n",
    "    md5_filename=str(md5_(url))\n",
    "    w=open('htmls\\\\'+md5_filename+'.html','w',encoding='utf-8')\n",
    "    w.write(str(soup))\n",
    "    w.close()\n",
    "    link_finish_num+=1\n",
    "    print('file_saved: ',md5_filename,' ',url)\n",
    "    global table\n",
    "    table.write(md5_filename+\",\"+url+','+str(baidu_find(url))+'\\n')\n",
    "    #then add new urls to wl\n",
    "    search_href(soup.body)\n",
    "    try:\n",
    "        for child in soup.body.contents:\n",
    "            try:\n",
    "                search_href(child)\n",
    "            except:\n",
    "                1\n",
    "            try:\n",
    "                for grand_child in child.contents:\n",
    "                    try:\n",
    "                        search_href(grand_child)\n",
    "                    except:\n",
    "                        1\n",
    "                    try:\n",
    "                        for ggc in grand_child.contents:\n",
    "                            try:\n",
    "                                search_href(ggc)\n",
    "                            except:\n",
    "                                1\n",
    "                            try:\n",
    "                                for sc in ggc.contents:\n",
    "                                    try:\n",
    "                                        search_href(sc)\n",
    "                                    except:\n",
    "                                        1\n",
    "                            except:\n",
    "                                1\n",
    "                    except:\n",
    "                        1\n",
    "            except:\n",
    "                1\n",
    "    except:\n",
    "        1        \n",
    "    \n",
    "def wl_deal():\n",
    "    heap2wl()\n",
    "    global waiting_list\n",
    "    while len(waiting_list)>0 :\n",
    "        time.sleep(0.01)#象征性地限制流速hhh\n",
    "        heap2wl()\n",
    "        cur_url=waiting_list.popleft() #deque后入前出\n",
    "        url_spider(cur_url.url)\n",
    "        global link_finish_num\n",
    "        if link_finish_num>=max_num:\n",
    "            break\n",
    "        #print(cur_url.url)###########################################debug\n",
    "        global abandon\n",
    "        if abandon==0:\n",
    "            heappush(heap,update_event(url=cur_url.url))    \n",
    "        else:\n",
    "            abandon=0\n",
    "\n",
    "def wl_add_first(url):\n",
    "    global waiting_list\n",
    "    waiting_list.append(url_class(url))\n",
    "    waiting_list=collections.deque(sorted(waiting_list))\n",
    "    global link_wait_num\n",
    "    link_wait_num+=1\n",
    "    md5_dec_first=int(md5_(url),16)\n",
    "    md5s[md5_dec_first]=1 #仅在新网页引入时判断了md5，所以起点网站md5要手动置为1\n",
    "    \n",
    "def run(urls):\n",
    "    for url in urls:\n",
    "        wl_add_first(url)\n",
    "    while True:\n",
    "        wl_deal()\n",
    "        if link_finish_num>=max_num:\n",
    "            print('all caught at least once')\n",
    "            global table\n",
    "            table.close()\n",
    "            break\n",
    "        time.sleep(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_saved:  e425fb6   www.elecfans.com\n",
      "file_saved:  39997ef   it.sohu.com\n",
      "file_saved:  a18b26c   bbs.elecfans.com\n",
      "file_saved:  c97bf4b   t.elecfans.com\n",
      "file_saved:  6168b3a   z.elecfans.com\n",
      "file_saved:  d02048a   webinar.elecfans.com\n",
      "file_saved:  74b6498   event.elecfans.com\n",
      "file_saved:  63c26ea   www.huaqiu.cn\n",
      "file_saved:  a95a3f3   www.tianyancha.com\n",
      "file_saved:  f346d45   ishare.iask.sina.com.cn\n",
      "file_saved:  e0c6660   www.qudong.com\n",
      "file_saved:  5d5f730   www.52rd.com\n",
      "file_saved:  dd464d4   smt.hqchip.com\n",
      "file_saved:  9ef33bc   www.chexun.com\n",
      "file_saved:  d092d05   www.bjx.com.cn\n",
      "file_saved:  d79fc37   www.cecb2b.com\n",
      "file_saved:  99602b7   www.eepw.com.cn\n",
      "file_saved:  32eafc5   www.cnmo.com\n",
      "file_saved:  d63f0e2   diy.elecfans.com\n",
      "file_saved:  7222504   www.dianyuan.com\n",
      "file_saved:  cdd3128   www.hqps.com\n",
      "file_saved:  2321ff9   www.gongchang.com\n",
      "file_saved:  be11d76   www.114ic.com\n",
      "file_saved:  f8a5aeb   www.cnledw.com\n",
      "file_saved:  44a489e   www.ic37.com\n",
      "file_saved:  2df1dfe   www.drivergenius.com\n",
      "file_saved:  c7229d7   b2b.makepolo.com\n",
      "file_saved:  396b96f   www.ebrun.com\n",
      "file_saved:  fd3d447   www.hqchip.com\n",
      "file_saved:  be66d55   www.bom.ai\n",
      "file_saved:  d351d87   www.eeworld.com.cn\n",
      "file_saved:  d615441   www.hqew.com\n",
      "file_saved:  29f4972   www.fanyedu.com\n",
      "file_saved:  b1bcb70   tech.china.com\n",
      "file_saved:  e5baf90   www.zwcad.com\n",
      "file_saved:  8af022e   www.xzbu.com\n",
      "file_saved:  e198edb   www.ofweek.com\n",
      "file_saved:  47a5c01   www.chinabidding.cn\n",
      "file_saved:  869c6f2   www.11467.com\n",
      "file_saved:  06e61fc   www.cheaa.com\n",
      "file_saved:  e9432ec   www.52solution.com\n",
      "file_saved:  5512a5f   www.diangon.com\n",
      "file_saved:  98896be   www.znj.com\n",
      "file_saved:  998f2a5   www.yzmg.com\n",
      "file_saved:  635e076   www.dzsc.com\n",
      "file_saved:  e7ec81d   www.eetop.cn\n",
      "file_saved:  61afa7b   www.qianzhan.com\n",
      "file_saved:  0431617   www.ximalaya.com\n",
      "file_saved:  5a8ed98   www.miitbeian.gov.cn\n",
      "abandoned:  www.elecfans.com\n",
      "abandoned:  it.sohu.com\n",
      "abandoned:  bbs.elecfans.com\n",
      "abandoned:  t.elecfans.com\n",
      "abandoned:  z.elecfans.com\n",
      "abandoned:  webinar.elecfans.com\n",
      "abandoned:  event.elecfans.com\n",
      "abandoned:  www.huaqiu.cn\n",
      "abandoned:  www.tianyancha.com\n",
      "abandoned:  ishare.iask.sina.com.cn\n",
      "abandoned:  www.qudong.com\n",
      "abandoned:  www.52rd.com\n",
      "abandoned:  smt.hqchip.com\n",
      "abandoned:  www.chexun.com\n",
      "abandoned:  www.bjx.com.cn\n",
      "abandoned:  www.cecb2b.com\n",
      "abandoned:  www.eepw.com.cn\n",
      "abandoned:  www.cnmo.com\n",
      "file_saved:  d63f0e2   diy.elecfans.com\n",
      "abandoned:  www.dianyuan.com\n",
      "file_saved:  cdd3128   www.hqps.com\n",
      "abandoned:  www.gongchang.com\n",
      "abandoned:  www.114ic.com\n",
      "abandoned:  www.cnledw.com\n",
      "abandoned:  www.ic37.com\n",
      "abandoned:  www.drivergenius.com\n",
      "abandoned:  b2b.makepolo.com\n",
      "abandoned:  www.ebrun.com\n",
      "abandoned:  www.hqchip.com\n",
      "abandoned:  www.bom.ai\n",
      "abandoned:  www.eeworld.com.cn\n",
      "abandoned:  www.hqew.com\n",
      "abandoned:  www.fanyedu.com\n",
      "abandoned:  tech.china.com\n",
      "abandoned:  www.zwcad.com\n",
      "abandoned:  www.xzbu.com\n",
      "abandoned:  www.ofweek.com\n",
      "abandoned:  www.chinabidding.cn\n",
      "abandoned:  www.11467.com\n",
      "abandoned:  www.cheaa.com\n",
      "abandoned:  www.52solution.com\n",
      "abandoned:  www.diangon.com\n",
      "abandoned:  www.znj.com\n",
      "abandoned:  www.yzmg.com\n",
      "abandoned:  www.dzsc.com\n",
      "abandoned:  www.eetop.cn\n",
      "abandoned:  www.qianzhan.com\n",
      "abandoned:  www.ximalaya.com\n",
      "abandoned:  diy.elecfans.com\n",
      "abandoned:  www.hqps.com\n",
      "file_saved:  5e0d7bf   www.sohu.com?strategyid=24\n",
      "file_saved:  b4ecd45   bbs.elecfans.com/group.php?mod=index\n",
      "file_saved:  0f7a17c   www.elecfans.com/application\n",
      "file_saved:  d093e4a   bbs.elecfans.com/zhuti_1218_1.html\n",
      "file_saved:  94cac14   t.elecfans.com/live\n",
      "abandoned:  bbs.elecfans.com/forum.php\n",
      "file_saved:  ce98215   bbs.elecfans.com/try.html\n",
      "file_saved:  489d390   bbs.elecfans.com/jishu_1924951_1_1.html\n",
      "file_saved:  54612f0   t.elecfans.com/topic\n",
      "file_saved:  0176759   t.elecfans.com/train\n",
      "all caught at least once\n"
     ]
    }
   ],
   "source": [
    "run([r'www.elecfans.com',r'it.sohu.com'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233.68538570404053\n"
     ]
    }
   ],
   "source": [
    "print(time.time()-begin_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_finish_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

## 三次大作业分别为索引、检索、爬虫。
#### 懒得整理了
### 第一次要求：   
针对CACM数据集，建立文档的倒排索引，以支持后续从系统中快速查找所需数据   
在索引中需要实现分词算法，可使用外部分词工具或自己简单实现    
支持Skip Pointer的AND queries    
支持短语查询，支持通配符   

### 第二次要求：   
输入关键字，输出系统检索到的文档集；检索模型不限；   
搜索词自动纠错、搜索词自动补全、交互界面友好、支持即时检索；    

### 第三次要求：   
*爬取一个自己专业领域网站的站点信息，给出爬取过程中以下问题（一些简单的基本问题）的解决方案并实现。  *
1. 网页抓全，区分明网暗网，新站发现。   
2. 网页抓新，网页更新或者消亡后及时更新，减少死链率以及提高实时性。  
3. 网页下载流速限制，避免将网页抓死。  
4. 网页避免重复抓取，更新链接时最近抓取过的网页不需要重复抓取。  
5. 网页抓取深度控制，避免单个网页过分抓取。  
6. 网页抓取的优先级，网页的不同链接需要有不同的优先级，需要判断优先级进行抓取。  
7. 镜像网页剔除，不同域名，相同内容的网页不需要重复抓取。   
8. 可视交互界面


